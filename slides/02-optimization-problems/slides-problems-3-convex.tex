
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\slvec}{\left(\zeta^{(1)}, \zeta^{(n)}\right)} % slack variable vector
\newcommand{\sli}[1][i]{\zeta^{(#1)}} % i-th slack variable
\newcommand{\scptxi}{\scp{\thetab}{\xi}} % scalar prodct of theta and xi
\newcommand{\alphav}{\bm{\alpha}} % vector alpha (bold) (basis fun coefficients)


\newcommand{\titlefigure}{figure_man/convex-example.png}
\newcommand{\learninggoals}{
\item TODO
\item TODO}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization}
\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Convex optimization problems}
\lecture{Optimization}
\sloppy


\begin{vbframe}{General Definition}

Consider the \textbf{optimization problem}
$$
\min_{\xv \in \mathcal{S}\subseteq \R^d} \fx
$$
with objective function
$$
f: \; \mathcal{S} \to \R.
$$

The problem is called \textbf{convex}

\begin{itemize}
	\item $f$ is a convex function
	\item $\mathcal{S}$ is a convex set. 
\end{itemize}

\lz 

\textcolor{red}{How do constraints need to look like such that $\mathcal{S}$ is convex? Linear constraints are okay; ...}

\end{vbframe}


\begin{vbframe}{Example 1: Quadratic forms}

\textcolor{red}{Discuss when a quadratic form corresponds to a convex optimization problem}

\end{vbframe}



\begin{frame}{Example 2: SVM dual}
	
We could directly solve the primal problem, but usually the SVM is solved in the \textbf{dual} formulation:  

\begin{eqnarray*}
	& \max\limits_{\alphav \in \R^n} & \sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_j\yi y^{(j)} \scp{\xi}{\xv^{(j)}} \\
	& \text{s.t. } & 0 \le \alpha_i \le C, \\
	& \quad & \sum_{i=1}^n \alpha_i \yi = 0,
\end{eqnarray*}
\pause
This is a convex quadratic program with box constraints and one linear constraint.
	
\end{frame}

\begin{frame}{Example 3: Risk Min. in Machine Learning}
	
	
\begin{itemize}
	\item $\D = \Dset$ denotes a dataset 
	where $\fxit$ is a model, parameterized by $\thetab$ (e.g. linear model).
	\item Let $\Lxy$ be the point-wise loss function which measures the error of a prediction $\fx$ compared to the true output $y$.
	\item We want to find the model which minimizes the \textbf{empirical risk}
	
	$$
	\risket = \frac{1}{n} \sumin L\left(\yi, \fxit\right).
	$$
\end{itemize}

\textcolor{red}{Formulate without $\theta$ and then explain why we usually parameterize the hypothesis space. }

\end{frame}	

\begin{vbframe}{Example 3: Risk Min. Machine learning}
		
Machine learning consists of three components: 

\begin{center}

  \textbf{Machine Learning} = $\underbrace{\textbf{Hypothesis Space + Risk}}_{\text{Formulating the optimization problem}}$ + $\underbrace{\textbf{Optimization}}_{\text{Solving it}}$
  
\end{center}

\lz

\begin{itemize}

  \item \textbf{Hypothesis Space:} Define (and restrict!) what kind of model 
  $f$ can be learned from the data.
  
  \item \textbf{Risk:} Define the risk function $\risket$ that quantifies how well a specific model performs on a given 
  data set via a suitable loss function $L$.
  
  \item \textbf{Optimization:} Solve the resulting optimization problem through optimizing the risk $\risket$ over the hypothesis space.
  
\end{itemize}

\framebreak 

The (computational) complexity of the optimization problem 

$$
\text{arg} \min_{\thetab} \risket
$$

and hence the choice of the numerical optimization algorithm is influenced by the model structure and the choice of the loss function:, i.e., smoothness, convexity. 		
\vspace*{-0.5cm}
\begin{center}
		\includegraphics[width=0.3\textwidth]{figure_man/ml_landscape.jpg} ~~~ \includegraphics[width=0.3\textwidth]{figure_man/log_reg.png}
	\begin{footnotesize}
		\newline
		Loss landscapes of ML problems. \\ Left: ResNet-56, right: Logistic regression with cross-entropy loss
		\newline
		Source: \url{https://arxiv.org/pdf/1712.09913.pdf}
	\end{footnotesize}
\end{center}	

\end{vbframe}

\begin{vbframe}{Example 3A: Normal regression}


\end{vbframe}

\begin{vbframe}{Example 3B: Logistic regression}


\end{vbframe}


\begin{vbframe}{Example 3C: Neural network}


\end{vbframe}

\begin{vbframe}{Why is convexity desirable?}

\end{vbframe}

\endlecture
\end{document}
