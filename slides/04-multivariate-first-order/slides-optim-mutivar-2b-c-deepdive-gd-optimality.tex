%<<setup-child, include = FALSE>>=
%library(knitr)
%library(microbenchmark)
%library(snow)
%library(colorspace)
%library(ggplot2)
%library(zoo)
%library(gridExtra)
%source("rsrc/functions.R")

%# mutate = ecr::mutate

%set_parent("../style/preamble.Rnw")
%@

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-nn}

%\newcommand{\titlefigure}{figure_man/}
\newcommand{\learninggoals}{
\item LEARNING GOAL 1
\item LEARNING GOAL 2}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization}
%\author{}
%\date{}

\begin{document}

	\lecturechapter{Deep Dive: Gradient Descent \& Optimality}
	\lecture{Optimization}
	
	
	
\begin{vbframe}{Gradient Descent and Optimality}
		
		\begin{minipage}{0.45\textwidth}
			\begin{small}
				\begin{itemize}
					\item GD is a greedy algorithm: In every iteration, it makes locally optimal moves.
					\vspace*{0.5mm}
					\item If $\riskt$ is \textbf{convex} and \textbf{differentiable}, and its gradient is Lipschitz continuous, GD is guaranteed to converge to the global minimum (for small enough step-size).  
					\vspace*{0.5mm}
					\item However, if $\riskt$ has multiple local optima and/or saddle points, GD might only converge to a stationary point (other than the global optimum), depending on the starting point. 
				\end{itemize}
			\end{small}
		\end{minipage}\hfill
		\begin{minipage}{0.5\textwidth}
			\begin{figure}
				\centering
				\scalebox{1}{\includegraphics{figure_man/gdes3.png}}
			\end{figure}
		\end{minipage}  
		\framebreak
		
			We assume that the gradient of the convex and differentiable function $f: \R^n \rightarrow \R$ is Lipschitz continuous with $L > 0$: 
		
			\begin{equation*}
			|| \nabla f(\bm{x}) - \nabla f(\bm{y}) || \le L ||\bm{x} - \bm{y} || \quad \text{ for all } x, y
			\end{equation*}
			
			This means that the gradient can't change arbitrarily fast. 
			
			\lz 
			
			Now we have a look at the convergence of gradient descent with a fixed step size $\alpha \leq 1/L$. \\
			\textbf{Convergence:} Let $f:\R^n \to \R$ be convex and have $L$-Lipschitz continuous gradients and assuming that the global minimum ${x}^\ast$ exists. Then gradient descent with $k$ iterations with a fixed step-size $\alpha \leq 1/L$ will yield a solution $f(x^k)$, which satisfies
			$$
				f({x}^k) - f({x}^\ast) \leq \frac{|| {x}^0 - {x}^\ast ||^2}{2\alpha k}
			$$
			
			This means, that GD converges with rate $\mathcal{O}(1/k)$.
			\framebreak 
		\end{vbframe}
		\begin{frame}{Gradient Descent and Optimality}
			\textbf{Proof: }
			The assumption that $\nabla f$ is Lipschitz continuous implies that $\nabla^2 f(x) \preccurlyeq L I$ for all $x$. The generalized inequality $\nabla^2 f(x) \preccurlyeq L I$ means that $L I - \nabla^2 f(x)$ is positive semidefinite. This means that $v^\top \nabla^2 f(u) v \leq L ||v||^2$ for any $u$ and $v$. 
			
			Therefore, we can perform a quadratic expansion of f around $\tilde{x}$ obtaining the following inequality: 

			\begin{eqnarray*}
				f(x) &\approx& f(\tilde{x}) + \nabla f(\tilde{x})^\top (x - \tilde{x}) + \textcolor{blue}{0.5  (x - \tilde{x})^\top \nabla^2 f(\tilde{x}) (x - \tilde{x})} \\
				& \leq & f(\tilde{x}) + \nabla f(\tilde{x})^\top (\tilde{x}) + 0.5 L ||x - \tilde{x}||^2,
			\end{eqnarray*}		
			as the blue term is at most $0.5 L ||x - \tilde{x}||^2$. This is called the descent lemma. 
			
			Now, we are doing one update via gradient descent with a step size $\alpha \leq 1/L$: 

			$$
			\tilde{x} = x^{t+1} = x^{t} - \alpha \nabla f(x^{t})
			$$ 
			and plug this in the descent lemma.
			

		\end{frame}
		\begin{vbframe}{Gradient Descent and Optimality}
			\begin{footnotesize}
			
			We get
			\vspace*{-0.3cm}
			\begin{eqnarray*}
			f(x^{t+1}) &\leq& f(x^t) - \nabla f(x^t)^\top(x^{t+1} - x^t) + \frac{1}{2}L ||x^{t+1} - x^t||^2 \\
			&=& f(x^t) + \nabla f(x^t)^\top(x^t - \alpha \nabla f(x^t) - x^t) + \frac{1}{2}L ||x^{t} - \alpha \nabla f(x^t) - x^t||^2 \\
			& = & f(x^t) - \nabla f(x^t)^\top \alpha  \nabla f(x^t) + \frac{1}{2}L ||\alpha \nabla f(x^t)||^2 \\
			&=& f(x^t) - \alpha ||\nabla f(x^t)||^2 + \frac{1}{2}L\alpha^2 ||\nabla f(x^t)||^2 \\
			&=& f(x^t) - (1 - \frac{1}{2} L \alpha)\alpha  ||\nabla f(x^t)||^2 \\
			&\le& f(x^t) - \frac{1}{2}\alpha ||\nabla f(x^t)||^2, 
			\end{eqnarray*}
		
			where we used $\alpha \leq 1/L$ and therefore $- (1 - \frac{1}{2} L \alpha) \leq \frac{1}{2} L \frac{1}{L} -1 = -\frac{1}{2}$.
						
			Since $\frac{1}{2} \alpha ||\nabla f(x^t)||^2$ is always positive unless $\nabla f(x) = 0$, it implies that $f$ strictly decreases with each iteration of GD until the optimal value is reached. So, it is a bound on guaranteed progress, when $\alpha \leq 1/L$. 
			\end{footnotesize}
			
			\framebreak
			
			Now, we bound $f(x)$ in terms of $f(x^*)$ and use that $f$ is convex: 
			
			$$
			f(x) \leq f(x^*) + \nabla f(x)^T (x - x^*)
			$$ 
			
			When we combine this and the bound derived before, we get
			
			\begin{eqnarray*}
				f(x^{t+1}) - f(x^*) &\leq& \nabla f(x)^\top (x-x^*) - \frac{\alpha}{2}||\nabla f(x)||^2 \\
				&=& \frac{1}{2 \alpha} \left( ||x-x^*||^2 - || x - x^* - \alpha \nabla f(x)||^2 \right) \\
				&=& \frac{1}{2 \alpha} \left( ||x-x^*||^2 - || x^{t+1} - x^* ||^2 \right)
			\end{eqnarray*}
		
		This holds for every iteration of GD. 
		
		\framebreak 
		
		Summing over iterations, we get: 
		
		\begin{eqnarray*}
			\sum_{t = 0}^{k} f(x^{t+1}) - f(x^*) &\leq& \sum_{t= 0}^{k} \frac{1}{2 \alpha} \left( ||x^{t}-x^*||^2 - || x^{t+1} - x^* ||^2 \right) \\
			&=& \frac{1}{2 \alpha}  \left( ||x^{0}-x^*||^2 - || x^{k} - x^* ||^2 \right) \\
			& \leq & \frac{1}{2 \alpha} \left( ||x^{0}-x^*||^2 \right),
		\end{eqnarray*}
	
		where we used that the LHS is a telescoping sum. In addition, we know that $f$ decreases on every iteration, so we can conclude that
		$$
		f({x}^k) - f({x}^\ast) \leq \frac{|| {x}^0 - {x}^\ast ||^2}{2\alpha k}
		$$
%		\textbf{Note: } It might not be that bad if we do not find the global optimum:  
%		
%		\begin{itemize}
%			\item We do not optimize the actual quantity of interest, i.e. the (theoretical) risk, but only an approximate version, i.e. the empirical risk. 
%			\item If the model class is very flexible, it might be disadvantageous to optimize too aggressively and increase the risk of overfitting. 
%			\item Early-stopping the optimization might even increase generalization performance. 
%		\end{itemize}
		
	\end{vbframe}	
	
	\endlecture
\end{document}