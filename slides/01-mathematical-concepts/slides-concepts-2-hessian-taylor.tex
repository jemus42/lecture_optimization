
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\usepackage{graphicx}


\newcommand{\titlefigure}{figure_man/Taylor2D/Taylor2D_1st100.png}
\newcommand{\learninggoals}{
\item Taylor series (Univariate)
\item Hessian Matrix
\item Taylor series (Multivariate)}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization}
\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Hessian Matrix \& Taylor Series}
\lecture{Optimization}
\sloppy
   
\begin{vbframe}{Definition Taylor's Theorem (univariate)}

\vspace*{-0.1cm}

Let $I \subseteq \R$ an open interval and $a, x \in I$ and $f \in \mathcal{C}^{m+1}(I,\R)$. Then 

\vspace*{-0.1cm}

$$f(x) = T_{m}(x,a) + R_{m}(x,a), \text{with}$$ 


    \begin{itemize}
      \item $m$-th \textbf{Taylor polynomial}: $T_{m}(x,a) \overset{(*)}{=} \sum_{k=0}^{m} \frac{f^{(k)}(a)}{k!}(x-a)^{k}$ 
      \item \textbf{Remainder term}: $R_m(x, a)$ (we will cover this term later)
    \end{itemize}

\vspace*{-0.3cm}

    \begin{figure}[htp]
        \centering
        \includegraphics[width=0.45\textwidth]{figure_man/taylor_univariate.png}
    \end{figure}

    \begin{footnotesize}
      $^{(*)}$ $T_{m}(x,a) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^{2} + ... + \frac{f^{(m)}(a)}{m!} (x - a)^m$
    \end{footnotesize}

    
\end{vbframe}

\begin{vbframe}{Definition Hessian Matrix}

The 2nd derivative of a multivariate function $f \in \mathcal{C}^2(\mathcal{S}, \R)$, $\mathcal{S}\subseteq \R^d$ (if it exists) is defined by the \textbf{Hessian} matrix

  \[ H(\xv) =\nabla^2 \fx =
  \Bigl(\frac{\partial^2 \fx}{\partial x_i \partial x_j}\Bigr)_{i,j=1\ldots d}\]
  
\lz 

\textbf{Example}: Let $f(x_1,x_2) = sin(x_1) \cdot cos(x_2)$. Then:

$$
H(\xv) = \begin{pmatrix}
\text{-cos}(x_2)\cdot\text{sin}(x_1) & \text{-cos}(x_1)\cdot\text{cos}(x_2) 
\\ \text{-cos}(x_1)\cdot\text{sin}(x_2) & \text{-cos}(x_2)\cdot\text{sin}(x_1) 
\end{pmatrix}
$$


\end{vbframe}

\begin{vbframe}{Hessian describes local curvature} 

Let w.l.o.g. $A(\xv) = \{\lambda_{1, \xv}, ..., \lambda_{d, \xv}\}$ be Eigenspectrum with $\lambda_{1, \xv} \le \lambda_{2, \xv} \le ... \le \lambda_{d, \xv}$ of $H(\xv)$; let $\bm{v}_{i, \xv}$ define the respective Eigenvectors. We can read from it: 

\begin{itemize}
  \item $\bm{v}_d$ points into the direction of largest curvature 
  \item $\bm{v}_1$ points into the direction of smallest curvature 
\end{itemize}

\vspace*{0.2cm}

\begin{footnotesize}

\textbf{Example (continued):} $H(\xv) = \begin{pmatrix}
\text{-cos}(x_2)\cdot\text{sin}(x_1) & \text{-cos}(x_1)\cdot\text{sin}(x_2) 
\\ \text{-cos}(x_1)\cdot\text{sin}(x_2) & \text{-cos}(x_2)\cdot\text{sin}(x_1) 
\end{pmatrix}.
$

\begin{itemize}
  \item $H(a)$, $a=(\frac{-\pi}{2},0)$: $\lambda_1 = \lambda_2 = 1$; $v_1 = (1, 0)^\top$, $v_2 = (0, 1)^\top$
  \item $H(b)$, $b=(0,\frac{-\pi}{2})$: $\lambda_1 = -1, \lambda_2 = 1$; $v_1 = (-1, 1)^\top$, $v_2 = (1, 1)^\top$
  \item \textcolor{blue}{$H(c), c=(\frac{-\pi}{2},0)$, : $\lambda_1 = \lambda_2 = 1$; $v_1 = (1, 0)^\top$, $v_2 = (0, 1)^\top$}
\end{itemize}

\end{footnotesize}

\vspace*{-0.5cm}

\begin{figure}[!tbp]
    \includegraphics[width=0.35\textwidth]{figure_man/hessian_3d.png}
    \includegraphics[width=0.35\textwidth]{figure_man/hessian_contour.png}
\end{figure} 

\end{vbframe}


\begin{vbframe}{Remainder term}

$$
  f(x) = T_m(x, a) + R_m(x, a)
$$

How close is $T_m(x,a)$ to $f(x)$?

\begin{itemize}
  \item Exact representation of $R_m(x,a)$:

  $$
    R_{m}(x, a) := \int_{a}^{x} \frac{f^{(k + 1)}(t)}{k!}(x - t)^k~\text{d}t
  $$
  \begin{footnotesize}
  (integral form of remainder; alternative formulas exist, but are not covered here.)
  \end{footnotesize}

  \item In order of magnitude: 
  $$
    R_{m}(\bm{a}) \in \order(\|\xv - \bm{a}\|^m) \text{ for } \xv \to \bm{a}
  $$
\end{itemize}

\framebreak 

\begin{itemize}
  \item Higher $m$ gives a better approximation
  \item The $m^{th}$ order taylor series is the best $m^{th}$ order approximation to $\fx$ near $\bm{a}$
\end{itemize}


\begin{columns}
\begin{column}{0.48\textwidth}
  \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st100.png}
\end{column}
\begin{column}{0.48\textwidth}
  \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-100.png}
\end{column}
\end{columns}

\begin{footnotesize}
Consider $T_2(\xv, \bm{a}) = f(\bm{a}) + \nabla f(\bm{a})^\top (\xv - \bm{a}) + \frac{1}{2}(\xv - \bm{a})^\top\bm{H}(\bm{a})(\xv - \bm{a})$. The first term ensures the \textbf{value} of $T_2$ and $f$ match at $\bm{a}$. The second term ensures the \textbf{slopes} of $T_2$ and $f$ match at $\bm{a}$. The third term ensures the \textbf{curvature} of $T_2$ and $f$ match at $\bm{a}$. 
\end{footnotesize}


\end{vbframe}


\begin{vbframe}{Multivariate Taylor series}

\textbf{Taylor's theorem (1st order)}: 

$$
  f(\xv) = \underbrace{f(\bm{a}) + \nabla f(\bm{a})^\top (\xv - \bm{a})}_{T_1(\xv, \bm{a})} + R_1(\xv, a) 
$$

\vspace*{-0.3cm}

\begin{footnotesize} \textbf{Example: } $\fx = \text{sin}(2x_1) + \text{cos}(x_2)$, $\bm{a} = (1, 1)^\top$. Since $\nabla \fx = \begin{pmatrix} 2\cdot\text{cos}(2x_1) \\ -\text{sin}(x_2) \end{pmatrix}$

\vspace*{-0.3cm}

\begin{eqnarray*}
  \fx &=& T_1(\xv) + R_1(\xv, \bm{a}) = f(\bm{a}) + \nabla f(\bm{a})^\top (\xv - \bm{a}) + R_1(\xv, \bm{a})\\ &=& \sin(2) + \cos(2) + (2 \cdot \cos(2), - \sin(1))\begin{pmatrix} x_1 - 1 \\ x_2 - 1\end{pmatrix} + R_1(\xv, \bm{a})
\end{eqnarray*}

\end{footnotesize}

\vspace*{-0.3cm}

\begin{columns}
  \begin{column}{0.4\textwidth}
%   \animategraphics[loop,controls,width=\linewidth]{7}{figure_man/Taylor2D/Taylor2D_1st}{0}{359}
    \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st100.png}
  \end{column}
  \begin{column}{0.4\textwidth}
    \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_1st301.png}
  \end{column}
\end{columns}

\framebreak 

\textbf{Taylor's theorem (2nd order)}: 

\vspace*{-0.7cm}

$$
  f(\xv) = \underbrace{f(\bm{a}) + \nabla f(\bm{a})^\top (\xv - \bm{a}) + \frac{1}{2}(\xv - \bm{a})^\top\bm{H}(\bm{a})(\xv - \bm{a})}_{T_2(\xv, \bm{a})} + R_2(\xv, a) 
$$

\begin{footnotesize}
\textbf{Example (continued):} $\fx = \text{sin}(2x_1) + \text{cos}(x_2)$, $\bm{a} = (1, 1)^\top$. Since

$$\nabla \fx = \begin{pmatrix} 2\cdot\text{cos}(2x_1) \\ -\text{sin}(x_2) \end{pmatrix}\text{ and } H(\xv) = \begin{pmatrix} -4 \text{sin}(2x_1) & 0 \\ 0 & -\text{cos}(x_2) \end{pmatrix} $$
 
we get 

\vspace*{-0.8cm}

  \begin{eqnarray*}
    \fx &=& T_1(\xv, \bm{a}) + \frac{1}{2}\begin{pmatrix}x_1 - 1 \\ x_2 - 1 \end{pmatrix}^\top \begin{pmatrix} -4 \text{sin}(2) & 0 \\ 0 & -\text{cos}(1) \end{pmatrix} \begin{pmatrix}x_1 - 1 \\ x_2 - 1 \end{pmatrix} + R_2(\xv, \bm{a})
  \end{eqnarray*}
  \vspace*{-0.2cm}
  \end{footnotesize}
  \begin{columns}
    \begin{column}{0.3\textwidth}
  %   \animategraphics[loop,controls,width=\linewidth]{7}{figure_man/Taylor2D/Taylor2D_2nd-}{0}{359}
      \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-100.png}
    \end{column}
    \begin{column}{0.3\textwidth}
      \includegraphics[width = \textwidth]{figure_man/Taylor2D/Taylor2D_2nd-301.png}
    \end{column}
  \end{columns}  


\end{vbframe}


\begin{vbframe}{Multivariate Taylor Series}  

What can be written down nicely for first and second order Taylor Series is (notationally) a bit more cumbersome for general $k$.

\lz 

Let $f: \R^d \to \R$, $f \in \mathcal{C}^k$ at $\bm{a} \in \R^d$. Then 

$$
  f(x) = T_m(\xv, \bm{a}) + R_m(\xv, \bm{a}), \text{ with}
$$

$$
  T_m(\xv,\bm{a}) = \sum_{|\bm{\alpha}| \le k} \frac{D^{\bm{\alpha}} f(\bm{a})}{{\bm{\alpha}}!} (\xv - \bm{a})^{\bm{\alpha}} \text{ and } \lim_{\xv \to \bm{a}} R_m(\xv,\bm{a}) = 0
$$

with $\bm{\alpha} \in \N^d$ and the multi-index notation
\begin{itemize}
  \item $|\bm{\alpha}| = \alpha_1 + \cdots + \alpha_d$
  \item $\bm{\alpha}! = \alpha_1! \cdots \alpha_d!$
  \item $\xv^{\bm{\alpha}} = x_1^{\alpha_1} \cdots x_d^{\alpha_d}$
  \item $D^{\bm{\alpha}} f = \frac{\partial^{|\bm{\alpha}|} f}{\partial x_1^{\alpha_1} \cdots \partial x_d^{\alpha_d}}$ 
\end{itemize}

\framebreak 

Let's check for $f: \R^2 \to \R$ and $k = 1$. We have for $|\alpha| \le 1$: 

\begin{itemize}
  \item $\alpha_1 = 0, \alpha_2 = 0$: $|\bm{\alpha}| = 0, \bm{\alpha}! = 1, \xv^{\bm{\alpha}} = 1, D^{\bm{\alpha}} f = 1$
  \item $\alpha_1 = 1, \alpha_2 = 0$: $|\bm{\alpha}| = 1, \bm{\alpha}! = 1, \xv^{\bm{\alpha}} = x_1, D^{\bm{\alpha}} f = \frac{\partial f}{\partial x_1}$
  \item $\alpha_1 = 0, \alpha_2 = 1$: $|\bm{\alpha}| = 1, \bm{\alpha}! = 1, \xv^{\bm{\alpha}} = x_2, D^{\bm{\alpha}} f = \frac{\partial f}{\partial x_2}$
\end{itemize}

and therefore: 

\begin{eqnarray*}
  T_m(\xv,\bm{a}) &=& \sum_{|\bm{\alpha|} \le k} \frac{D^{\bm\alpha} f(\bm{a})}{\bm{\alpha}!} (\xv - \bm{a})^{\bm{\alpha}} \\ &=& \frac{1 \cdot f(\bm{a})}{1} \cdot 1 + \frac{\partial f}{\partial x_1}(\bm{a}) (x_1 - a_1) + \frac{\partial f}{\partial x_2}(\bm{a}) (x_2 - a_2) \\
  &=& f(a) + \begin{pmatrix} \frac{\partial f}{\partial x_1} (\bm{a})\\ \frac{\partial f}{\partial x_2}(\bm{a})\end{pmatrix}^\top \begin{pmatrix} x_1 - a_1 \\ x_2 - a_2\end{pmatrix} = f(\bm{a}) + \nabla f(\bm{a})^\top (\xv - \bm{a}). 
\end{eqnarray*}


\end{vbframe}



  \endlecture
\end{document}