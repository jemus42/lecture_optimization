\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-mbo}

\newcommand{\titlefigure}{figure_man/sms_plot.pdf}
\newcommand{\learninggoals}{
\item Multicriteria Optimization
\item Taxonomy
\item ParEGO, EHI, SMS-EGO
}

\title{Optimization in Machine Learning}
%\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Bayesian Optimization:\\ Multicriteria Optimization}
\lecture{Optimization in Machine Learning}

\begin{vbframe}{Multicriteria Bayesian Optimization}
\begin{columns}
\begin{column}{0.4\textwidth}

\vspace*{-0.8cm}

\input{figure_man/gear.tex}
%http://tex.stackexchange.com/questions/6135/how-to-make-beamer-overlays-with-tikz-node

\tikzset{
  %Style of the black box
  bbox/.style={draw, fill=black, minimum size=3cm,
  label={[white, yshift=-1.25em]above:$in$},
  label={[white, yshift=1.25em]below:$out$},
  label={[rotate = 90, xshift=1em, yshift=0.5em]left:Black-Box}
  },
  multiple/.style={double copy shadow={shadow xshift=1.5ex,shadow
  yshift=-0.5ex,draw=black!30,fill=white}}
}
\begin{center}
\begin{tikzpicture}[>=triangle 45, semithick]
\node[bbox] (a) {};
\draw[thick, shift=({-0.4cm,0.2cm}), draw = white](a.center) \gear{18}{0.5cm}{0.6cm}{10}{2}; \draw[thick, shift=({0.4cm,-0.3cm}), draw = white](a.center) \gear{14}{0.3cm}{0.4cm}{10}{2};
{
  \draw[<-] (a.120) --++(90:1.5em) node [above] {$x_1$};
  \draw[<-] (a.100) --++(90:1.5em) node [above] {$x_2$};
  \draw[<-] (a.80) --++(90:1.5em) node [above] {$\ldots$};
  \draw[<-] (a.60) --++(90:1.5em) node [above] {$x_d$};
}
{
  \draw[->] (a.240) --++(90:-1.5em) node [below] {$f_1(\xv)$};
  \draw[->] (a.300) --++(90:-1.5em) node [below] {$f_2(\xv)$};
}
\end{tikzpicture}
\end{center}
\end{column}

\begin{column}{0.60\textwidth}
\begin{eqnarray*}
  && f: \mathcal{S} \rightarrow \R^m\\
  \min \limits_{\xv \in \mathcal{S}} && f(\xv) = \left(f_1(\xv), \ldots, f_m(\xv)\right)
\end{eqnarray*}
\begin{itemize}
  \item A configuration $\xv$ \textbf{dominates} ($\prec$) $\tilde{\xv}$ if
\begin{eqnarray*}
  \forall i \in \{ 1, ..., m\}: && f_i(\xv) \leq f_i(\tilde{\xv})\\
  \text{and}~\exists j \in \{1, ..., m\}: && f_j(\xv) < f_j(\tilde{\xv})
\end{eqnarray*}
\item Set of non-dominated solutions:
  \begin{small}
  \begin{align*}
    \mathcal{P} := \{\xv \in \mathcal{S} | \nexists \tilde{\xv} \in \mathcal{S}: \tilde{\xv} \prec \xv \}
\end{align*}
\end{small}
\item Pareto set $\mathcal{P}$, Pareto front $ f(\mathcal{P})$
\item{Goal:} Find $\hat{\mathcal{P}}$ of non-dominated points that estimates the true set $\mathcal{P}$
\end{itemize}
\end{column}
\end{columns}

\framebreak

Example Pareto front:

% FIXME: plot: y1 vs x, y2 vs x, y2 vs y1 (all colored based on dominated)
\vspace{+0.45cm}
\begin{center}
  \includegraphics[width = 0.5\textwidth]{figure_man/multicrit_0.png}
\end{center}
\end{vbframe}

\begin{frame}{Taxonomy}
\begin{figure}[t]
\centering
\vspace{-0.2cm}
\includegraphics[width = 0.6\textwidth]{figure_man/FlowchartMBMO.pdf}
% \vspace{-0.2cm}
\end{figure}
  Horn, Wagner, Bischl et al. (2014).
\end{frame}

\begin{vbframe}{ParEGO}

 \begin{enumerate}
   \item Scalarize standardized objectives using the augmented Tchebycheff norm
   \begin{equation*}
   \label{eq:tcheby}
     \max\limits_{i \in \{1, \ldots, m\}} w_i f_i(\xv) + \rho \sum\limits_{i = 1}^m w_i f_i(\xv)
   \end{equation*}
   with weight vector $\mathbf{w}$ drawn uniformly from the set of evenly distributed weight vectors $\mathcal{W}$
   \item Fit SM on the scalarized objective function
   \item Proceed to use any standard single-objective acquisition function (EI, PI, LCB, ...)
 \end{enumerate}

\framebreak
% FIXME: also plot true scalarized function in left plot and right top
ParEGO Example, initial design and true Pareto front in black ...
\vspace{1cm}
\begin{center}
  \includegraphics[width = 0.5\textwidth]{figure_man/multicrit_1.png}
\end{center}

\framebreak
... standardize objectives, obtain scalarized objective via augmented Tchebycheff norm, fit SM and optimize EI ...
\vspace{+0.45cm}
\begin{center}
  \includegraphics[width = 0.9\textwidth]{figure_man/multicrit_2.png}
\end{center}

\framebreak
... note that the specific scalarization is different at each iteration
\begin{center}
  \includegraphics[width = 0.9\textwidth]{figure_man/multicrit_3.png}
\end{center}

\end{vbframe}

\begin{frame}{EHI}

\begin{itemize}
  \item Individual models for each objective $f_i$
  \item Single-objective optimization of aggregating acquisition function: \\
  Calculate expected hypervolume improvement when adding the candidate to the current front approximation
\end{itemize}

\end{frame}

\begin{frame}{SMS-EGO}

\begin{itemize}
\item Individual models for each objective $f_i$
\item Single-objective optimization of aggregating acquisition function: \\
  Calculate contribution of the confidence bound of candidate to the current front approximation
\end{itemize}

\begin{columns}

\begin{column}{0.55\textwidth}
\begin{itemize}
  \item Calculate LCB for each objective
  \item Measure contribution with regard to the hypervolume improvement
  \item For $\varepsilon$-dominated ($\prec_{\varepsilon}$) solutions, a penalty is added
\end{itemize}
\vfill
\end{column}

\begin{column}{0.45\textwidth}

\includegraphics[page = 1]{figure_man/hv_plot.pdf}<1>
\includegraphics[page = 1]{figure_man/hv_contr_plot.pdf}<2>
\includegraphics[page = 1]{figure_man/sms_plot.pdf}<3>

\end{column}

\end{columns}
\end{frame}

\endlecture
\end{document}
