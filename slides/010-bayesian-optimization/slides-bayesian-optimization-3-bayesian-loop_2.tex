\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-mbo}

\newcommand{\titlefigure}{figure_man/bayesian_loop_sm_normal_fmin.png}
\newcommand{\learninggoals}{
\item Bayesian surrogate modeling
\item Standard acquisition functions
}

\title{Optimization in Machine Learning}
%\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Bayesian Optimization:\\ Posterior Uncertainty and Acquisition Functions II}
\lecture{Optimization in Machine Learning}

\begin{vbframe}{Probability of Improvement}

\textbf{Goal}: Find $\xvsi[t+1]$ that maximizes the \textbf{Probability of Improvement} (PI):

$$
  a_{\text{PI}}(\xv) = \P(Y(\xv) < \fmin) = \Phi\left(\frac{\fmin - \fh(\xv)}{\sh(\xv)}\right)
$$

where $\Phi(\cdot)$ denotes the distribution function of a standard normal random variable\\

\vspace{1em}

PI is more complex than LCB and typically makes assumptions regarding the posterior predictive distribution under a SM

\vfill

\begin{footnotesize}
\textbf{Note:} The probability of improvement is $0$ for points that have already been evaluated. This can be seen analytically: For a visited point $\sh(\xv) = 0$ and $\fh(\xv) = f(\xv) \ge \fmin$, and thus $\fmin - \fh(\xv) \le 0$. Thus

$$
  \Phi\left(\frac{\fmin - \fh(\xv)}{\sh(\xv)}\right) = \Phi\left(- \infty\right) = 0.
$$

\end{footnotesize}

\framebreak

PI illustration for $\xv = 0$ given a SM yielding a normally distributed posterior predictive distribution\\

\vspace{0.45em}

\begin{minipage}[b]{0.45\textwidth}
  \includegraphics[width = \textwidth]{figure_man/bayesian_loop_sm_normal_fmin.png}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\textwidth}
  \includegraphics[width = \textwidth]{figure_man/bayesian_loop_pi_0.png}
\end{minipage}

\begin{footnotesize}
Left: The green vertical line represents $\fmin$ Right: $a_{\text{PI}}(\xv)$ is given by the black area
\end{footnotesize}

\framebreak

The PI does not take the size of the improvement into account\\
Often it will propose points close to the current $\fmin$\\
\vspace{1em}
We use the PI (red line) to propose the next point ...
\vspace{-1em}
\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_1.png}
\end{center}

The red point depicts $\argmax_{\xv \in \mathcal{S}} a_{\text{PI}}(\xv)$

\framebreak

... evaluate that point, refit the SM and propose the next point

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_2.png}
\end{center}

The grey point visualizes the candidate we choose to evaluate in the previous iteration

\end{vbframe}

\begin{frame}{Probability of Improvement}

\only<1>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_3.png}
\end{center}
}

\only<2>{
In our example, using the PI results in spending plenty of time optimizing the local optimum ...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_4.png}
\end{center}
}

\only<3>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_5.png}
\end{center}
}

\only<4>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_6.png}
\end{center}
}

\only<5>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_7.png}
\end{center}
}

\only<6>{
... eventually, we explore other regions ...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_8.png}
\end{center}
}

\only<7>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_pi_9.png}
\end{center}
}

\end{frame}

\begin{vbframe}{Expected Improvement}

\textbf{Goal:} Propose $\xvsi[t+1]$ that maximizes the \textbf{Expected Improvement} (EI): 

\vspace*{-0.5cm}

\begin{eqnarray*}
  % FIXME: Expected value with respect to \fh i.e. the GP predictive posterior distribution
  a_{\text{EI}}(\xv) &=& \E(\max\{\fmin - Y(\xv), 0\}) \\
\end{eqnarray*} 

\vspace*{-0.5cm}

EI is more complex than PI and typically also makes assumptions regarding the posterior predictive distribution under a SM\\

\vspace{1em}

Note that the improvement is bounded from below by $0$. Uncertainty only enters in the case of real improvement $\fmin - Y(\xv) > 0$

\framebreak

If $Y(\xv) \sim \mathcal{N}\left(\fh(\xv), \sh^2(\xv)\right)$, we can express the EI in closed-form as: 

$$
a_{\text{EI}}(\xv) = (\fmin-\fh(\xv)) \Phi \Big(\frac{\fmin - \fh(\xv)}{\sh(\xv)}\Big) + \sh(\xv) \phi\Big(\frac{\fmin-\fh(\xv)}{\sh(\xv)}\Big), 
$$

where $\Phi(\cdot)$ and $\phi(\cdot)$ denote the distribution and density function of a standard normal random variable

\vfill

\begin{footnotesize}
\textbf{Note:} The EI is $0$ for points that have already been evaluated. For a visited point $\fh(\xv) = f(\xv) \ge \fmin$, and thus $\fmin - \fh(\xv) \le 0$ and $\max\{\fmin - \fh(\xv), 0\} = 0$.
\end{footnotesize}

\framebreak

We use the EI (red line) to propose the next point ...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_1.png}
\end{center}

The red point depicts $\argmax_{\xv \in \mathcal{S}} a_{\text{EI}}(\xv)$

\framebreak

... evaluate that point, refit the SM and propose the next point

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_2.png}
\end{center}

The grey point visualizes the candidate we choose to evaluate in the previous iteration

\end{vbframe}

\begin{frame}{Expected Improvement}

\only<1>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_3.png}
\end{center}
}

\only<2>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_4.png}
\end{center}
}

\only<3>{
...

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_5.png}
\end{center}
}

\end{frame}

\begin{frame}{Expected Improvement}

The EI is capable of exploration and quickly proposes promising points in areas we haven't visited yet

\begin{center}
  \includegraphics[width = 0.6\textwidth]{figure_man/bayesian_loop_6.png}
\end{center}

This is also a result of the well-calibrated uncertainty estimates of the SM (in this example a GP)

\end{frame}

\begin{frame}{Acquisition Functions: Comparison}

\begin{itemize}
  \item It can be shown that (under some mild conditions) Bayesian Optimization with a GP as SM and EI is a \textbf{global optimizer}
  \begin{itemize}
    \item That means: Convergence to the \textbf{global} (!) optimum is guaranteed given an unlimited budget
  \end{itemize}
  \item This cannot be proven for the PI or the LCB
  \item From a theoretical perspective, this suggests choosing the EI as acquisition function
  \item In practical applications, however, time to convergence is too long to rely on that theoretical property
  \item LCB often can work very well in practice
\end{itemize}

\end{frame}

\begin{frame}{Acquisition Functions: Outlook}

Many more acquisition functions exist:

\begin{itemize}
  \item Entropy based: Entropy search, predictive entropy search, max value entropy search
  \item Knowledge Gradient
  \item Thompson Sampling
  \item ...
\end{itemize}

\end{frame}

\endlecture

\end{document}
