\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}


\newcommand{\titlefigure}{figure_man/convex_programs.png}
\newcommand{\learninggoals}{
\item Definition
\item Structure
}


%\usepackage{animate} % only use if you want the animation for Taylor2D

\title{Optimization in Machine Learning}
%\author{Bernd Bischl}
\date{}

\begin{document}

\lecturechapter{Evolutionary Algorithms}
\lecture{Optimization in Machine Learning}
\sloppy
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{vbframe}{Evolutionary Algorithms}

\textbf{Evolutionary algorithms} (EA) are a class of stochastic, metaheuristic optimization techniques whose mode of operation is inspired by the evolution of natural organisms.

\vspace{0.5cm}
\footnotesize
History of evolutionary algorithms:

\begin{itemize}
\item \textbf{Genetic algorithms}: Use binary problem representation, therefore closest to the biological model of evolution.
\item \textbf{Evolution strategies}: Use direct problem representation, e.g., vector of real numbers.
\item \textbf{Genetic programming}: Create structures that convert an input into a fixed output (e.g. computer programs); solution candidates are represented as trees.
\item \textbf{Evolutionary programming}: Similar to genetic programming, but solution candidates are not represented by trees, but by finite state machines.
\end{itemize}

The boundaries between the terms become increasingly blurred and are often used synonymously.
\end{vbframe}

\begin{vbframe}{Structure of an evolutionary algorithm}

\begin{figure}
\centering
\begin{tikzpicture}[node distance=1cm, auto,]
%nodes
\node (init) {Initialize population};
\node[below = 0.3cm of init](rating1) {Eval population};
\node[below = 0.3cm of rating1](selection1) {Parent selection};
\node[below = 0.3cm of selection1](variation) {Variation};
\node[below = 0.3cm of variation](rating2) {Eval offspring};
\node[below = 0.3cm of rating2](selection2) {Survival selection};
\node[below = 0.3cm of selection2](stop) {Stop};
\node[below = 1cm of stop](dummy2) {};
\node[below = 0.2cm of stop](dummy3) {};
\node[right = 0.01cm of dummy3](dummy4) {yes};
\node[left = 1.1cm of rating2](dummy1) {no};
\draw[->] (init) to (rating1) node[midway, above]{};
\draw[->] (rating1) to (selection1) node[midway, above]{};
\draw[->] (selection1) to (variation) node[midway, above]{};
\draw[->] (variation) to (rating2) node[midway, above]{};
\draw[->] (rating2) to (selection2) node[midway, above]{};
\draw[->] (selection2) to (stop) node[midway, above]{};
\draw[->] (stop) to (dummy2) node[midway, above]{};
\draw[->] (stop) to [bend left=90, looseness=2](selection1) node[midway, above]{};
\end{tikzpicture}
\end{figure}

\end{vbframe}

\begin{vbframe}{Notation and Terminology}

\footnotesize
\begin{itemize}
\item A chromosome is a set of parameters which encodes a proposed solution to the problem that the genetic algorithm is trying to solve. The chromosome is often represented as a binary string, although a wide variety of other data structures are also used.\\
\item The set of all solutions is known as the population.
\end{itemize}
\vspace{0.5cm}
\normalsize
\begin{center}
\begin{tabular}{ c | c}
    \textbf{Symbols} & \textbf{EA Terminology} \\[0.05cm]
    \hline \\[0.01cm]
    solution candidate $\bm{x}\in \mathcal{S}$ & Chromosome of an individual \\[0.1cm]
    $\bm{x}_j$  & $j$-th gene of chromosome\\[0.1cm]
    Set of candidates $P$ with $\mu = |P|$ & Population and size \\[0.1cm]
    $\lambda$ & Number of generated offsprings\\[0.1cm]
    $f: \mathcal{S} \to \R$ & Fitness function
\end{tabular}
\end{center}

%$$f(\bm{x}) = \widehat{GE}_{\mathcal{D}_{test}}\left(\inducer(\mathcal{D}_{train},\bm{x})\right)$$


\end{vbframe}

\begin{vbframe}{Step 1: Initialize population}
    \begin{itemize}
            \item An evolutionary algorithm is started by generating an initial population $P = \{\bm{x}^{(1)}, ..., \bm{x}^{(\mu)}\}$.
            \item Usually, we sample this uniformly at random.
            \item We could introduce problem prior knowledge via a smarter init procedure.
            \item This population is evaluated, i.e., the objective function is computed for every individual in the initial population.
            \item The initialization can have a large influence on the quality of the found solution, so many EAs employ \textit{restarts} with new randomly generated populations.
    \end{itemize}

\end{vbframe}

\begin{vbframe}{Step 2: parent selection}
\footnotesize
The first step of an iteration chooses $\lambda$ parents, that create offspring for the next step.

\medskip

Possibilities for selection of parents:
\begin{itemize}
\item \textbf{Neutral selection: }choose individual with a probability $1/\mu$.
\item \textbf{Fitness-proportional selection: }draw individuals with probability proportional to their fitness.
\item \textbf{Tournament selection: }randomly select $k$ individuals for a "tournament group". Of the drawn individuals, the best one (according to fitness value) is then chosen. In order to draw $\lambda$ individuals, the procedure must be performed $\lambda$-times.
\end{itemize}
\vspace*{-0.2cm}
\begin{figure}
  \includegraphics[width = 7cm, height = 2.5cm ]{figure_man/tournament_selection.png}
\end{figure}
\end{vbframe}

\begin{vbframe}{Step 3: variation}

New individuals are now generated from the parent population. This is done by

\begin{itemize}
\item Recombination/Crossover: combine two parents into one offspring.
\item Mutation: (locally) change an individual.
\end{itemize}

Recombination and mutation are not always performed both; sometimes only one operation is performed.

\vspace{0.3cm}
\begin{center}
\begin{figure}
  \includegraphics[width = 8cm, height = 2.6cm ]{figure_man/rec-and-mut.png}\\
\end{figure}
\end{center}

\end{vbframe}

\begin{vbframe}{Recombination for numeric}

Two individuals $\bm{x}, \bm{\tilde x} \in \R^d$ in numerical representation can be recombined as follows:
\begin{itemize}
\item \textbf{Uniform crossover}: choose gene $j$ with probability $p$ of 1st parent and probability $1-p$ of 2nd parent.
\item \textbf{Intermediate recombination}: new individual is created from the mean value of two parents $\frac{1}{2}(\bm{x} + \bm{\tilde x})$.
\item \textbf{Simulated Binary Crossover (SBX)}: generate \textbf{two offspring} based on

$$
\bm{\bar x} \pm \frac{1}{2} \beta (\bm{\tilde x} - \bm{x})
$$

with $\bm{\bar x} = \frac{1}{2} (\bm{x} + \bm{\tilde x})$ and $\beta$ randomly sampled from a certain distribution.
\end{itemize}

\end{vbframe}

\begin{vbframe}{Mutation for numeric}

\footnotesize
\textbf{Mutation:} individuals are changed, for example for $\bm{x} \in \R^d$
\begin{itemize}
\item \textbf{Uniform mutation:} choose a random gene $\bm{x}_j$ and replace it with a value uniformly distributed (within the feasible range).
\item \textbf{Gauss mutation:} $\bm{\tilde{x}} = \bm{x} \pm \sigma \mathcal{N}(0, \boldsymbol{I})$
\item \textbf{Polynomial mutation:} polynomial distribution instead of normal distribution
\end{itemize}
\begin{center}
\begin{figure}
  \includegraphics[height = 3.5cm, width = 4cm]{figure_man/polynomial_mutation.png}\\
  \scriptsize{Source: K. Deb, Analysing mutation schemes for real-parameter genetic algorithms, 2014}
\end{figure}
\end{center}

\end{vbframe}

\begin{vbframe}{Recombination for bit strings}
\footnotesize
Two individuals $\bm{x},\bm{\tilde{x}} \in \{0, 1\}^d$ encoded as bit strings can be recombined as follows:

  \begin{itemize}
  \normalsize
  \item \textbf{1-point crossover}: select crossover $k \in \{1, ..., d - 1\}$ randomly and the first $k$ bits from 1st and the last $d-k$ bits from 2nd parent.
  \footnotesize
  \begin{center}
  \begin{tabular}{c @{\hspace{2\tabcolsep}} *{6}{c}}
    \textcolor{red}{1} & \textcolor{blue}{1}  & & \textcolor{red}{1}  \\
    \textcolor{red}{0} & \textcolor{blue}{0}  & &  \textcolor{red}{0}  \\ \cmidrule{1-4}
    \textcolor{red}{0} & \textcolor{blue}{1}  &$\Rightarrow$ & \textcolor{blue}{1}  \\
    \textcolor{red}{1} & \textcolor{blue}{1}  & &   \textcolor{blue}{1}  \\
    \textcolor{red}{1} & \textcolor{blue}{0}  & &   \textcolor{blue}{0}
  \end{tabular}
  \end{center}
  \normalsize
  \item \textbf{Uniform crossover}: select bit $j$ with probability $p$ of 1st parent and $1-p$ of 2nd parent.
  \footnotesize
  \begin{center}
  \begin{tabular}{c @{\hspace{2\tabcolsep}} *{6}{c}}
    \textcolor{red}{1} & \textcolor{blue}{0}  & & \textcolor{red}{1}  \\
    \textcolor{red}{0} & \textcolor{blue}{0}  & &  \textcolor{blue}{0}  \\ 
    \textcolor{red}{0} & \textcolor{blue}{1}  &$\Rightarrow$ & \textcolor{blue}{1}  \\
    \textcolor{red}{0} & \textcolor{blue}{1}  & &   \textcolor{blue}{1}  \\
    \textcolor{red}{1} & \textcolor{blue}{0}  & &   \textcolor{red}{1}
  \end{tabular}
  \end{center}
  \normalsize
  \end{itemize}
  
\end{vbframe}

\begin{vbframe}{Mutation for bit strings}
  An individual $\bm{x} \in \{0, 1\}^d$ encoded as a bit string can be mutated as follows:
  \vspace{0.5cm}
  
  \begin{itemize}
  \item \textbf{Bitflip}: for each index $j \in \{1, ..., d\}$: bit $j$ is flipped with probability $p \in (0,1)$.
  \end{itemize}
  \begin{center}
  \begin{tabular}{c @{\hspace{2\tabcolsep}} *{5}{c}}
  \\[1ex]
   1  &               & \textcolor{red}{0}  \\
   0  &               & 0  \\
   0  & $\Rightarrow$ & 0  \\
   0  &               & \textcolor{red}{1}  \\
   1  &               & 1
  \end{tabular}
  \end{center}
  \end{vbframe}
  
\begin{vbframe}{Step 4: Survival selection}
  Now individuals are chosen who survive. Two common strategies are:
  \begin{itemize}
  \item \textbf{$(\mu, \lambda)$-selection:} We select from the $\lambda$ descendants the $\mu$ best ($\lambda \ge \mu$ necessary).\\
  \textbf{But:} best overall individual can get lost!
  \item \textbf{$(\mu + \lambda)$-selection:} $\mu$ parents and $\lambda$ offspring are lumped together and the $\mu$ best individuals are chosen.\\
  Best individual safely survives.
  \end{itemize}

\end{vbframe}


\begin{vbframe}{Example of an evolutionary algorithm}
\footnotesize
In the following, a (simple) EA is shown on the 1-dim Ackley function, optimized on $[-30, 30]$. Usually, for the optimization of a function $f:\R^d \to \R$ individuals are coded as real vectors $\bm{x}_j \in \R^d$, so here we use simply one real number as a chromosome.

\begin{center}
\begin{figure}
  \includegraphics[height = 6cm, width = 7cm]{figure_man/1dim-ackley-func.png}
\end{figure}
\end{center}

\end{vbframe}

\begin{vbframe}{Example of an evolutionary algorithm}

Randomly init population with size $\mu = 20$.
\vspace{0.5cm}

\begin{center}
\begin{figure}
  \includegraphics[height = 6cm, width = 7cm]{figure_man/1dim-ackley-func-2.png}
\end{figure}
\end{center}

\end{vbframe}

\begin{vbframe}{Example of an evolutionary algorithm}
We choose $\lambda = 5$ offspring by neutral selection (red individuals).

\vspace{0.5cm}

\begin{center}
\begin{figure}
  \includegraphics[height = 6cm, width = 7cm]{figure_man/neutral-selec.png}
\end{figure}
\end{center}

\end{vbframe}


\begin{vbframe}{Example of an evolutionary algorithm}
%We use a Gaussian mutation with $\sigma = 2$ and don't apply a recombination.
Using a Gaussian mutation with $\sigma=2$, without a recombination.
\vspace{0.5cm}

\begin{center}
\begin{figure}
  \includegraphics[height = 6cm, width = 7cm]{figure_man/gaussian-mutation.png}
\end{figure}
\end{center}

\end{vbframe}


\begin{vbframe}{Example of an evolutionary algorithm}
We use a $(\mu + \lambda)$ selection. The selected individuals are green.

\vspace{0.5cm}

\begin{center}
\begin{figure}
  \includegraphics[height = 6cm, width = 7cm]{figure_man/selection.png}
\end{figure}
\end{center}


\end{vbframe}

\begin{vbframe}{Evolutionary Algorithms}
\footnotesize
\textbf{Advantages}
  \begin{itemize}
    \item Conceptually simple, yet powerful enough to solve complex problems (including HPO)
    \item All parameter types possible in general
    \item Highly parallelizable (depends on $\lambda$)
    \item Allows customization via specific variation operators
  \end{itemize}
\textbf{Disadvantages}
    \begin{itemize}
      \item Less theory available (for realistic, complex EAs)
      \item Can be hard to get balance between exploration and exploitation right
      \item Can have quite a few control parameters, hard to set them correctly\\
      \item Customization necessary for complex problems
      \item Not perfectly suited for expensive problems like HPO, 
            as quite a higher number of evaluations is usually
            needed for appropriate convergence / progress
    \end{itemize}
    % \item Stagnation: Optimization process does not progress any more %FIXME: JR: Isn't that the same as the point below?
    % \item Premature Convergence: Algorithm converges to a single solution, which is not as good as expected
    % \item Diversity of population structures: Loss of population diversity for solving complex optimization problems

\end{vbframe}

%\begin{vbframe}{Example}

%In the following, methods for the individual steps of an evolutionary algorithm are presented.

%\lz

%These are demonstrated using the one-dimensional Ackley function, which we want to optimize on the $[-30, 30]$ interval.

%\lz

%In this case, each individual has exactly one chromosome. The chromosome is (obviously) encoded as a real number: $x_i \in \R$.

%\lz

%Usually for the optimization of a function $f:\R^n \to \R$ individuals are coded as real vectors $\bm{x}_i \in \R^n$.


%We start with a randomly selected population $\mathcal{P} = \{\bm{x}_1, ..., \bm{x}_\mu\}$ of the size $\mu = 20$ and rate it. The fitness function in this case is the function we want to minimize.

%\end{vbframe}


%\begin{vbframe}{Step 2: parent selection}
%\footnotesize
%In the first step of an iteration, $\lambda$ parents are chosen, who create offspring in the next step.

%\medskip

%Possibilities for selection of parents:
%\begin{itemize}
%\item \textbf{Neutral selection: }choose individual with a probability $1/\mu$.
%\item \textbf{Fitness-proportional selection: }draw individuals with probability proportional to their fitness.
%\item \textbf{Tournament Selection: }randomly select $k$ individuals for a "Tournament Group". Of the drawn individuals, the best one (with the highest fitness value) is then chosen. In order to draw $\lambda$ individuals, the procedure must be performed $\lambda$-times.
%\end{itemize}
%\vspace*{-0.2cm}
%\begin{figure}
%  \includegraphics[width = 7cm, height = 2.5cm ]{figure_man/tournament_selection.png}
%\end{figure}
%\framebreak


%\begin{vbframe}{Mutation for numeric representations}

%\textbf{Mutation:} individuals are changed, for example for $\bm{x} \in \R^n$
%\begin{itemize}
%\item \textbf{Uniform mutation:} choose a random gene $x_i$ and replace it with a value uniformly distributed (within the feasible range).
%\item \textbf{Gauss mutation}: $\bm{\tilde x} = \bm{x} \pm \sigma \mathcal{N}(\bm{0}, \id)$
%\item \textbf{Polynomial mutation:} polynomial distribution instead of normal distribution

%\begin{center}
%\begin{figure}
 % \includegraphics[height = 3.5cm, width = 4cm]{figure_man/polynomial_mutation.png}\\
  %\scriptsize{Source: K. Deb, Analysing mutation schemes for real-parameter genetic algorithms, 2014}
%\end{figure}
 %\end{center}

 %\framebreak

%More exact:

%$$
%{\tilde x_{i}} = x_{i} + (x_{i,upper} - x_{i,lower}) \delta_{i}
%$$

%with $x_{i,upper} (x_{i,lower})$ as upper (lower) bound for $x_{i}$.

%$\delta_{i}$ results as:

%\footnotesize
%$$
%\delta_{i} =
%\begin{cases}
%[2r_{i}+(1-2r_{i})(1-\delta)^{\eta_{m}+1}]^{\frac{1}{\eta +1}} -1, & r_{i} < 0.5 \\
%1 - [2(1-r_{i})+2(r_{i}-\frac{1}{2})(1-\delta)^{\eta_{m}+1}]^{\frac{1}{\eta_{m} +1}}, &  \text{else.}
%\end{cases}
%$$
%with  $\delta = \frac{min\{(x_{i} - x_{i,lower}), (x_{i,upper}-x_{i})\}}{x_{i,upper} - x_{i,lower}}$.

%\normalsize

%\lz

%Here $r_{i} \in [0,1]$ is a uniformly distributed number, $\eta_{m}$ is the distribution index of the mutation and is chosen by the user.\\
% Remark: A $\eta_{m}$ of the order of $\eta_{m} \in [20,100]$ is common.
%\normalsize
%\end{itemize}



%\lz

%In our example, we have chosen a Gauss mutation with $\sigma = 2$, we do not apply a recombination.


%\end{vbframe}

%\begin{vbframe}{Mutation for bit strings}

%For example, an individual $\bm{x} \in \{0, 1\}^n$ encoded as a bit string can be mutated as follows:

%\lz

%\textbf{Mutation:}
%\begin{itemize}
%\item \textbf{Bitflip}: for each index $k \in \{1, ..., n\}$: bit $k$ is flipped with probability $p \in (0,1)$.
%\item If $(a)$ is an arbitrary bit sequence to which a bitflip mutation is applied, $(b)$ is obtained.
%\end{itemize}

%\footnotesize
%\begin{center}
%\begin{tabular}{c @{\hspace{2\tabcolsep}} *{5}{c}}
 % &
%  \itshape (a) &
 % \itshape " " &
  %\itshape " " &
  %\itshape " " &
  %\itshape (b)

%\\[1ex]
%" " & 1 & " " & " " & "  " & \textcolor{red}{0}  \\
%" " & 0 & " " & " " & "  " & 0  \\
%" " & 0 & " " & $\Rightarrow$ & "  " & \textcolor{red}{1}  \\
%" " & 1 & " " & " " & "  " & \textcolor{red}{0}  \\
%" " & 1 & " " & " " & "  " & 1
%\end{tabular}
%\end{center}
%\normalsize

%\end{vbframe}



\endlecture
\end{document}

